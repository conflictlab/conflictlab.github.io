\documentclass[twocolumn]{erdc}
\usepackage{lipsum,url,multicol, wrapfig,lipsum}
\usepackage{natbib}
\usepackage{subcaption} 

\usepackage{geometry}
\usepackage{subcaption}
\usepackage[justification=justified,singlelinecheck=false]{caption}

%\geometry{margin=1in}
\usepackage[]{ragged2e}
\usepackage{graphicx, comment}
\usepackage{enumitem}
\setlist{nosep}
\usepackage{float}
\usepackage{stfloats}
\usepackage{setspace, hyperref}  \newcommand{\HRule}{\rule{\textwidth}{0.5mm}}


\begin{document}
\onecolumn
\frontmatter

\reportnum{PaCE/2024/02/sb}

\program{}

\title{Forecasting Report}

\subtitle{September 2024}

\date{{}}
\author{}

\affiliation{PaCE \\Trinity College Dublin, The University of Dublin\\
College Green\\
Dublin 2, Ireland\\
\url{https://www.forecastlab.org/}\\
\begin{figure}[H]
    \centering
    \begin{subfigure}[t]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Fig/LOGO_ERC-FLAG_FP.png}
    \end{subfigure}\\
    \begin{subfigure}[t]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Fig/Trinity_Main_Logo.jpg}\end{subfigure}\\
    \begin{subfigure}[t]{0.49\textwidth}
        \centering        \includegraphics[width=\textwidth]{Fig/IRC LOGO_RGB.jpg}
    \end{subfigure}
\end{figure}
}





\affiliation{}

\coverart{Fig/slide1}

\reporttype{}

\additionalinfo{}

%\begin{abstract}%
%We find that .....
%\end{abstract}

%\disclaimer{Some other disclaimer}

\preparedfor{Thomas Schincariol \& Thomas Chadefaux} 

\contractnum{This project has received funding from the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation programme (grant agreement No 101002240).}




\monitoredby{The contents of this report are not to be used for
advertising, publication, or promotional purposes. Citation of trade
names does not constitute an official endorsement or approval of the
use of such commercial products. All product names and trademarks
cited are the property of their respective owners. The findings of
this report are not to be construed as an official position of Trinity College Dublin unless so designated by other authorized documents.}

%\preparedfor{}

\maketitle

\twocolumn
\newgeometry{left=1.45cm,right=1.45cm, bottom=2cm, top=2cm}
\justifying

\begin{onecolumn} 
\noindent 
\HRule \\
This report presents conflict fatalities forecasts for the period from February to July 2024. Using data from the Uppsala Conflict Data Program (UCDP), available through January 2024, we generated predictions at the country-month level. These forecasts aim to provide early-warning insights into conflict zones by estimating fatalities in the upcoming six months. Our approach leverages advanced predictive models that incorporate historical data on conflict patterns to make these predictions.

In this report, we compare our forecasts with actual observed fatalities and assess the accuracy of our model across various regions. This analysis helps identify areas where the model performed well and where it can be improved, offering insights that could inform strategic decision-making in conflict prevention and resource allocation.
Key findings include:

\begin{itemize} 
\item \textbf{High-accuracy regions}: The model performed well in high-intensity conflict zones such as Ukraine and the Democratic Republic of Congo, with predictions closely matching actual outcomes. 
\item \textbf{Over/underpredictions}: Underpredictions were seen in regions like Russia and Papua New Guinea, while overpredictions occurred in Iraq, Iran, and Venezuela. 
\item \textbf{Benchmark comparison}: Our model showed strong performance, achieving higher accuracy in approximately 70\% of cases compared to other forecasting models, highlighting different strengths across models depending on the region and conflict intensity.
\end{itemize}
 \HRule 
%\noindent\makebox[\linewidth]{\rule{\paperwidth}{0.4pt}}


\section*{Forecasts vs. Actual Outcomes.}

%\renewcommand{\thefigure}{5}
\begin{figure*}[!ht]
    \centering
\includegraphics[width=\textwidth]{Fig/dtw_best.png}
    \caption{Comparison of observed conflict fatalities (grey) and predicted fatalities (red) in selected countries for the forecast period from February to July 2024. This figure highlights where the model’s predictions closely aligned with actual outcomes and where discrepancies occurred.}
    \label{fig:best_dtw}
\end{figure*}

\begin{figure}[H]
    \centering
    % Top map: predictions
    \begin{subfigure}[t]{\textwidth}
        \centering
        \includegraphics[width=0.8\textwidth]{Fig/pred_map.pdf}
        \caption{Predicted Fatalities}
        \label{fig:predictions}
    \end{subfigure}

    \vspace{0.5cm} % Adjust vertical space between images

    % Middle map: truth (observed)
    \begin{subfigure}[t]{\textwidth}
        \centering
        \includegraphics[width=0.8\textwidth]{Fig/true_map.pdf}
        \caption{Observed Fatalities (Truth)}
        \label{fig:truth}
    \end{subfigure}
%
    \vspace{0.5cm} % Adjust vertical space between images
%
    % Bottom map: difference
    \begin{subfigure}[t]{\textwidth}
        \centering
        \includegraphics[width=0.8\textwidth]{Fig/Fore_map.png}
        \caption{Percentage error.}
        \label{fig:difference}
    \end{subfigure}

    \caption{(a) Predicted conflict fatalities, (b) observed conflict fatalities (truth), and (c) percentage error between predictions and observed outcomes for the period from February to July 2024. Red in the error map indicates underprediction, while blue highlights overprediction.}
    \label{fig:comparison_maps}
\end{figure}




\end{onecolumn}
%
%\
\section*{Forecasting Performance}

\begin{multicols*}{2}
%
\begin{figure}[H]
    \centering    \includegraphics[width=1\linewidth]{Fig/Fore_all.png}
    \caption{Logarithmic scale comparison of predicted conflict fatalities (grey) and observed fatalities for the 30 countries with the highest fatality counts. Red indicates regions where the model underpredicted fatalities, while blue highlights regions where the model overpredicted fatalities. The log scale emphasizes discrepancies in regions with extreme values.}
    \label{fig:Fore_all}
\end{figure}
\par Our model performed well overall in forecasting major conflicts, though we tend to underpredict---a common issue in conflict forecasting due to skewed data with many zero values (Figure \ref{fig:Fore_all}). Notable discrepancies include underpredictions in Russia and Papua New Guinea and overpredictions in Iraq, where conflicts are of lower intensity.
\par Figure \ref{fig:difference} maps the percentage error (Mean Absolute Percentage Error, MAPE) for countries with more than 15 observed fatalities. MAPE measures how much our predictions differ from the actual fatalities, with a lower value indicating more accurate predictions. The largest overpredictions were in Iran, Iraq, and Venezuela, while Papua New Guinea and Angola saw the largest underpredictions. However, these countries had relatively low fatality counts (e.g., 17 in Venezuela, 22 in Angola, 51 in Iran, and 103 in Iraq). More accurate predictions were seen in sub-Saharan Africa, Central and South America, and Asia, with Ukraine and most of the Middle East also showing low error rates, except for Iraq and Iran.
%
\begin{comment}
\begin{figure*}[t!]
    \centering
    \includegraphics[width=0.8\textwidth]{Fig/Fore_map.png}
    \caption{Map of the percentage of error. If the color is red, our model underpredicts and blue overpredicts. Only countries with more than 15 fatalities observed are included, while others are hatched in grey.}
    \label{fig:Fore_map}
\end{figure*}
\end{comment}

\section*{Classification}

We grouped countries according to how the number of conflict-related fatalities changed during the six-month forecast period compared to the previous six months. The change is measured using a ratio between fatalities during the forecast period and those from the prior six months:

This approach helps us understand whether violence in each country is rising, staying the same, or declining over time (see methodological appendix for details). 
\vspace{1em}
%\begin{wrapfigure}{l}{8cm}

Figure \ref{heatmap} presents the confusion matrix for our predictions. Observed outcomes were: 65\% decrease, 25\% increase, and 10\% stable. The model achieved 72\% accuracy, with 12\% adjacent class predictions and 16\% opposite class predictions.
%\par Figure \ref{heatmap_continu} shows the observed ratios on the x-axis and the predicted ratios on the y-axis. The grey dotted line represents a perfect prediction. The regression line falls slightly below the perfect line, consistent with our earlier finding that most predictions tend to underestimate actual values. However, overall, the two histograms of the ratio distributions—observed and predicted—are fairly similar.


\begin{figure}[H]
\centering
\includegraphics[width=0.8\linewidth]{Fig/Heatmap.png}
\caption{Confusion matrix displaying the performance of the model in classifying countries based on conflict fatality trends (decrease, stable, increase). The x-axis shows predicted classifications, while the y-axis shows actual outcomes. Accurate predictions are along the diagonal, while errors are off-diagonal. This matrix helps evaluate the model’s accuracy in predicting changes in conflict dynamics.}\label{heatmap}
\end{figure} 




\begin{comment}
\renewcommand{\thefigure}{4}
\begin{figure}[H]
\includegraphics[width=8cm]{Fig/heat_continu.png}
\caption{Join Scatter plot of Observed ratio (in x) and Predicted (in y). The dotted red line represents the perfect prediction.}\label{heatmap_continu}
\end{figure} 




%\section*{Dynamic Error}

\renewcommand{\thefigure}{\arabic{figure}}
\begin{figure*}[!t]
    \centering
    \includegraphics[width=\textwidth]{Fig/dtw_worse.png}
    \caption{Observed values (grey) and Prediction (red) of the country with DTW>1}
    \label{fig:worse_dtw}
\end{figure*}
\end{comment}

%In this section, we focus less on prediction error, as typically done in forecast studies, and more on the overall dynamic of the data. To achieve this, we use the Dynamic Time Warping (DTW) distance between the normalized predicted and observed values. This metric helps align sequences that may differ in timing or length but share the same general pattern. For instance, if we predict a rise in fatalities in June, but a similar rise occurs in July, the DTW distance will adjust for this shift, resulting in a low distance score. This approach emphasizes how well we captured the overall six-month trend, without heavily penalizing predictions that are delayed by one or two months.



%Figure 5 shows the Dynamic Time Warping (DTW) values for countries with at least 15 observed fatalities during the six-month period. The highest DTW values, indicating poor dynamic predictions, are found in Mexico, Burkina Faso, the Democratic Republic of Congo (DRC), Costa Rica, and Papua New Guinea. Fig. \ref{fig:best_dtw} displays the cases where our model accurately predicted the correct dynamic. The model performed well in South America, Asia, the Middle East, and most African countries. In nations like Somalia, Nigeria, Kenya, and Cameroon, the model captured the correct trend, though with a lag of one or two months in some instances. Additionally, in Iran and Benin, the model successfully predicted a decrease in fatalities, despite earlier trends showing a concerning rise in January. Typically, such prior increases lead to higher forecasted values, but our model correctly identified these cases. 

%On the contrary, Fig. \ref{fig:worse_dtw} highlights the worst cases, where DTW exceeds 1. In some cases, such as Costa Rica, Angola, and Papua New Guinea, the prior dynamics were flat, with mostly zero values. These situations are particularly difficult to forecast, as there are no signs of potential danger in the autoregressive data, making it nearly impossible for the model to predict a rise in fatalities. In other cases, like Mexico, Mozambique, and the DRC, the model failed to capture the correct trend, but these are relatively isolated.

\section*{Benchmark comparison}
%
We compare our model's performance to two other leading open-source monthly fatality forecasts:  the \href{https://viewsforecasting.org/}{Violence \& Impacts Early-Warning System (VIEWS)} \citep{Hegre2021JPR} and \href{https://conflictforecast.org/}{Conflict Forecast} (CF) \cite{Mueller2024}. These models have different primary objectives and features. VIEWS provides forecasts for up to 36 months and offers both country-level and more detailed predictions.\footnote{Here, we rely on Views' Fatalities002 forecasts \citep{Hegre2022FCDO}. For this comparison, we adapted our model to consider only state-based fatalities, as Views provides forecasts exclusively for state-based events. This may explain differences observed when comparing the benchmarks for the same country.} We only compare its first six months of forecasts to match our model's timeframe.  ConflictForecast predicts total fatalities for the next three months, assesses armed conflict risk, and estimates the likelihood of violence. Fatality prediction is just one aspect of their model. Our comparison focuses solely on fatality predictions for the first six months. This is not a competition to determine the best model, but rather an effort to understand how our approach fits within the broader landscape of conflict forecasting.
%
\begin{figure}[H]
\includegraphics[width=0.85\linewidth]{Fig/Views.png}
\caption{Log ratio of the Mean Squared Error (MSE) comparing our model’s predictions to the VIEWS model’s predictions. Positive values (in red) indicate that our model performed better, while negative values (in blue) show that VIEWS performed better in predicting conflict fatalities.}\label{Views}
\end{figure} 
%
\begin{figure*}[!b]
    \centering
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
\includegraphics[width=0.9\textwidth]{Fig/ConflictForecast_1.png}
        \caption{February--April}
        \label{CF1}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
\includegraphics[width=0.9\textwidth]{Fig/ConflictForecast_2.png}
        \caption{May--July}
        \label{CF2}
    \end{subfigure}
    \caption{Comparison of Absolute Error (Log ratio) between our model and ConflictForecast for two periods: February--April 2024 (left) and May--July 2024 (right). Positive values (red) indicate better performance of our model, while negative values (blue) show better accuracy of the ConflictForecast model.}
    \label{fig:CF_comparison}
\end{figure*}
%
%
\par We use the log ratio of the mean squared error (MSE) to measure each model's accuracy. This approach shows how much each model's predictions deviate from the actual fatalities. A positive log ratio (shown in red) means our model's predictions were closer to reality, while a negative ratio (in blue) indicates that the other model was more accurate.  
\par Our model outperforms VIEWS in 75\% of cases and CF in 70\% and 74\% of cases for the first and second periods, respectively. We perform particularly well in high-intensity conflicts like Ukraine and Pakistan. However, VIEWS shows better accuracy in some high-intensity cases (e.g., Burkina Faso, Sudan) and low-intensity conflicts (e.g., Indonesia, Benin). CF excels in Iraq for both periods and outperforms our model in several high-intensity zones (Israel, Ukraine, Sudan, Mexico) during the second period, possibly due to more recent data access (for the second period, CF had access to data up to April 2024, which our model did not).
\end{multicols*}

\clearpage
\newpage
\section*{Forecast data}
Our full forecast are available to download at \url{https://github.com/ThomasSchinca/Pace-map-risk/tree/main/Historical_Predictions}

\section*{Appendix: Methodology}

This section provides an overview of the methodology used to generate conflict fatalities forecasts for the period from February to July 2024. The forecasts were produced using data from the Uppsala Conflict Data Program (UCDP) up to January 2024. The goal of our approach is to forecast fatalities on a country-month level by applying advanced predictive models that capture both static and dynamic aspects of conflict patterns. The full methodology and additional technical details can be found in \cite{chadefaux2022shape,chadefaux2023automated,schincariol2024temporal,Schincariol2024,Schincariol_JoF}. %\href{https://21024c1e-d73a-4ff3-9f63-41c5a94563f5.usrfiles.com/ugd/21024c_18c99c39372b45d7858c2ce35f8b15f6.pdf}{here}.

\subsection*{Data Sources}

The primary source for conflict event data is the UCDP Georeferenced Event Dataset (GED). This dataset provides a detailed and comprehensive account of conflict events involving government forces, non-state actors, and organized armed groups, including fatality counts. The dataset is updated regularly and includes information on event locations, time periods, and actors involved.  For our forecast model, we use UCDP-GED data available through January 2024. The data was aggregated to the country-month level. 

\subsection*{Forecasting Models}

Our forecasting methodology involves two core models: a \textbf{Baseline Model} and a \textbf{Dynamic Temporal Patterns (DTP) Model}. Both models were designed to forecast conflict fatalities over a six-month period, but they use different techniques to capture conflict trends.
%
\paragraph*{\underline{Baseline Model}.} The Baseline Model employs the ViEWS early-warning system, a well-established and leading approach for forecasting conflict. Key features of ViEWS include:
\begin{itemize}
    \item \textbf{Lagged conflict variables:} Fatalities from prior months are included as lagged variables to account for continuity in conflict behavior. This allows the model to leverage historical patterns of conflict for prediction.
    \item \textbf{Geopolitical and economic features:} Variables such as proximity to ongoing conflicts in neighboring countries, GDP per capita, oil rents, and political instability (e.g., regime change, exclusion of political groups) are incorporated to assess the broader conflict risk.
    \item \textbf{Demographic factors:} Population size, urbanization, and the proportion of young males are used as predictors, as these have been shown to correlate with conflict intensity.
\end{itemize}
    
\paragraph*{\underline{Dynamic Temporal Patterns (DTP) Model.}} The DTP Model introduces a dynamic aspect to forecasting by focusing on the variability and sequence alignment of conflict patterns. Unlike the Baseline Model, which relies on static relationships, the DTP Model uses Dynamic Time Warping (DTW) to align sequences of conflict fatalities across different timeframes. This technique is useful for identifying and predicting shifts in conflict intensity, as it allows for flexibility in the timing of events.

Key components of the DTP Model:
\begin{itemize}
    \item \textbf{Dynamic Time Warping (DTW)}: DTW compares the predicted sequence of fatalities with the observed sequence, aligning them even if there is a lag or shift in the occurrence of peaks in fatalities. This reduces penalization for short-term misalignment in predictions.
    \item \textbf{Non-linear Time Dependency}: The model accounts for non-linear relationships between conflict events and fatalities over time. It is particularly suited for regions with rapidly changing conflict dynamics, such as escalating or de-escalating conflicts.
    \item \textbf{Pattern Recognition}: By analyzing historical conflict trajectories, the model identifies similar patterns of conflict evolution and uses these to forecast the next phase of the conflict.
\end{itemize}

\subsection*{Model Training and Validation}

Both models were trained on historical UCDP data spanning several years, up to January 2024. To ensure robustness, the models were cross-validated using k-fold validation, and performance metrics were calculated for each fold to evaluate the predictive accuracy across different conflict regions and time periods. The models were then tested on the forecasting period (February to July 2024), comparing predicted fatalities with the actual observed fatalities during this time. Key metrics used for validation included:
\begin{itemize}
    \item \textbf{Mean Squared Error (MSE)}: A standard measure to evaluate the difference between predicted and actual fatality counts.
    \item \textbf{Mean Absolute Percentage Error (MAPE)}: Used to measure the percentage error between predicted and observed values, providing a normalized metric for comparison across countries with different fatality scales.
    \item \textbf{Dynamic Time Warping Distance}: For the DTP model, we used DTW distance as a performance metric, which measures how well the predicted fatality sequence matches the observed sequence in terms of timing and pattern.
\end{itemize}

\subsection*{Classification of Conflict Trends}

Countries were classified into three distinct groups based on the ratio of fatalities observed during the forecast period (February to July 2024) to those in the previous six months (August 2023 to January 2024). We use classification instead of relying solely on MSE because classification provides clearer insights into conflict trends. While MSE measures prediction error, it can reward overly conservative predictions that minimize error without capturing real shifts in conflict dynamics. Classification, by contrast, groups countries based on whether fatalities are increasing, stable, or decreasing. This approach highlights broader trends and helps decision-makers prioritize responses where conflict is intensifying, offering a more actionable framework than MSE alone.

\begin{itemize}
    \item \textbf{Decreasing Conflict}: Countries with a ratio of fatalities less than 0.8, indicating that fatalities decreased during the forecast period.
    \item \textbf{Stable Conflict}: Countries with a ratio between 0.8 and 1.2, signifying that fatalities remained relatively stable.
    \item \textbf{Increasing Conflict}: Countries with a ratio greater than 1.2, indicating an increase in fatalities during the forecast period.
\end{itemize}

\subsection*{Evaluation and Benchmarking}

Our models were evaluated not only against observed data but also through benchmarking with other conflict forecasting models, such as ViEWS and ConflictForecast. Performance was assessed based on both overall accuracy and the ability to capture dynamic shifts in conflict intensity. In particular, the DTP model demonstrated advantages in regions where conflicts experienced sudden escalations or de-escalations, while the Baseline Model performed well in regions with consistent conflict patterns. 

\bibliographystyle{plain}
\bibliography{biblio}
\end{document}
